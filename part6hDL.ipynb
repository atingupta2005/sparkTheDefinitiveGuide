{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark: The Definitive Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 6: Advanced Analytics and Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagesDL = '/Users/grp/sparkTheDefinitiveGuide/data/deep-learning-images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Chapter #31 - Deep Learning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-  learns from unstructured data with high dimensions like images, audio, and text\n",
    "\n",
    "### Deep Neural Networks:\n",
    "-  graph of nodes with weights and activation functions\n",
    "-  nodes are organized into _layers_\n",
    "-  layers are connected to previous layers in the network\n",
    "-  layers are stacked together with many nodes to recognize complex signals in the input\n",
    "-  networks are trained to associate certain inputs with certain outputs by tuning weights and values of each node\n",
    "\n",
    "### Use Cases:\n",
    "-  computer vision\n",
    "-  speech processing\n",
    "-  NLP\n",
    "-  facial recognition\n",
    "-  image (brand) detection\n",
    "-  sound patterns\n",
    "\n",
    "### Spark Deep Learning Methods:\n",
    "-  Inference:\n",
    "    -  take pretrained model and apply to large dataset via Spark's parallel processing\n",
    "    -  typically call _map_ function on DL library (ex: TensorFlow) to trigger distributed inference\n",
    "-  Featurization and Transfer Learning:\n",
    "    -  use existing model as a _featurizer_ via \"transfer learning\" method (leverages a pre-trained model and then modifying it to better fit new use case)\n",
    "-  Model Training:\n",
    "    -  train from scratch via Spark's parallel processing\n",
    "    -  perform ETL/FE via Spark's parallel processing and export model to THEN run on a single machine using libraries like TensorFlow or Keras for training\n",
    "\n",
    "### Deep Learning Libraries:\n",
    "-  MLlib Neural Network Support:\n",
    "    -  MLlib's **ml.classification.MultilayerPerceptronClassifier** deep neutral network\n",
    "    -  uses sigmoid activation function and output layer with softmax activation function\n",
    "-  TensorFrames:\n",
    "    -  https://github.com/databricks/tensorframes\n",
    "    -  helps pass data between Spark DFs and TensorFlow\n",
    "    -  better alternative to using _map_ function on DL library via Python\n",
    "-  BigDL:\n",
    "    -  https://github.com/intel-analytics/BigDL\n",
    "    -  distributed DL framework optimized to run on CPUs rather than typically GPUs\n",
    "-  TensorFlowOnSpark:\n",
    "    -  https://github.com/yahoo/TensorFlowOnSpark\n",
    "    -  ability to train TensorFlow models in parallel on Spark clusters\n",
    "-  DeepLearning4J:\n",
    "    -  https://deeplearning4j.org/docs/latest/deeplearning4j-spark-training\n",
    "    -  Java/Scala DL library for both single node and cluster distributed training\n",
    "-  Deep Learning Pipelines:\n",
    "    -  https://github.com/databricks/spark-deep-learning\n",
    "    -  https://spark-packages.org/package/databricks/spark-deep-learning\n",
    "    -  Databricks package integrating DL functionality into Spark's ML Pipelines API via distributed computing\n",
    "    -  currently only available via Python language for integrating with TensorFlow and Keras libraries\n",
    "    -  Install Dependencies:\n",
    "        -  **if using cluster make sure everything is installed on driver machine and all worker machines**\n",
    "        -  TensorFrames => https://github.com/databricks/tensorframes\n",
    "        -  TensorFlow => https://www.tensorflow.org\n",
    "        -  Keras => https://keras.io\n",
    "        -  h5py => http://www.h5py.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Chapter #31 Exercises (DL)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Terminal Packages Example_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npyspark --packages databricks:tensorframes:0.5.0-s_2.11,databricks:spark-deep-learning:1.2.0-spark2.3-s_2.11\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pyspark --packages databricks:tensorframes:0.5.0-s_2.11,databricks:spark-deep-learning:1.2.0-spark2.3-s_2.11\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Spark DL Import Example_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.image import ImageSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = false)\n",
      " |    |-- width: integer (nullable = false)\n",
      " |    |-- nChannels: integer (nullable = false)\n",
      " |    |-- mode: integer (nullable = false)\n",
      " |    |-- data: binary (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_df = ImageSchema.readImages(imagesDL)\n",
    "image_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Transfer Learning Example_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.image import ImageSchema\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading images\n",
    "tulips_df = ImageSchema.readImages(imagesDL + \"/tulipsSample\").withColumn(\"label\", lit(1))\n",
    "daisy_df = ImageSchema.readImages(imagesDL + \"/daisySample\").withColumn(\"label\", lit(0))\n",
    "\n",
    "# train/test splits\n",
    "tulips_train, tulips_test = tulips_df.randomSplit([0.6, 0.4])  \n",
    "daisy_train, daisy_test = daisy_df.randomSplit([0.6, 0.4])\n",
    "train_df = tulips_train.unionAll(daisy_train)\n",
    "test_df = tulips_test.unionAll(daisy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from sparkdl import DeepImageFeaturizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using transformer (DeepImageFeaturizer):\n",
    "    # leverages pre-trained model called Inception:\n",
    "        # neural network used to identify patterns in images\n",
    "featurizer = DeepImageFeaturizer(inputCol=\"image\", outputCol=\"features\", modelName=\"InceptionV3\")\n",
    "\n",
    "# logistic regression learning algorithm is being used to train model\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.05, elasticNetParam=0.3, labelCol=\"label\")\n",
    "p = Pipeline(stages=[featurizer, lr])\n",
    "\n",
    "p_model = p.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "# classification evaluation metrics\n",
    "tested_df = p_model.transform(test_df)\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(tested_df.select(\"prediction\", \"label\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import expr, udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(origin='file:/Users/grp/sparkTheDefinitiveGuide/data/deep-learning-images/daisySample/4571353297_5634177744_n.jpg', p_1=0.9436311454723025, label=0)\n",
      "Row(origin='file:/Users/grp/sparkTheDefinitiveGuide/data/deep-learning-images/daisySample/4571993204_5b3efe0e78.jpg', p_1=0.9191149810614544, label=0)\n",
      "Row(origin='file:/Users/grp/sparkTheDefinitiveGuide/data/deep-learning-images/tulipsSample/367020749_3c9a652d75.jpg', p_1=0.10012947989947016, label=1)\n",
      "Row(origin='file:/Users/grp/sparkTheDefinitiveGuide/data/deep-learning-images/daisySample/130684941_d1abfa3be6_m.jpg', p_1=0.6930696737582386, label=0)\n",
      "Row(origin='file:/Users/grp/sparkTheDefinitiveGuide/data/deep-learning-images/daisySample/11642632_1e7627a2cc.jpg', p_1=0.5809598871642018, label=0)\n",
      "Row(origin='file:/Users/grp/sparkTheDefinitiveGuide/data/deep-learning-images/tulipsSample/11642632_1e7627a2cc.jpg', p_1=0.5809598871642018, label=1)\n",
      "Row(origin='file:/Users/grp/sparkTheDefinitiveGuide/data/deep-learning-images/daisySample/20619292635_9857a12d54.jpg', p_1=0.2649125874394392, label=0)\n",
      "Row(origin='file:/Users/grp/sparkTheDefinitiveGuide/data/deep-learning-images/tulipsSample/11746080_963537acdc.jpg', p_1=0.7933831428462236, label=1)\n",
      "Row(origin='file:/Users/grp/sparkTheDefinitiveGuide/data/deep-learning-images/tulipsSample/14067761295_7cfe6a42e9.jpg', p_1=0.8296896607873973, label=1)\n",
      "Row(origin='file:/Users/grp/sparkTheDefinitiveGuide/data/deep-learning-images/tulipsSample/391364011_5beaaa1ae2_m.jpg', p_1=0.8399909416171388, label=1)\n"
     ]
    }
   ],
   "source": [
    "# find rows/images where mistakes were made in training\n",
    "# a simple UDF to convert the value to a double\n",
    "def _p1(v):\n",
    "  return float(v.array[1])\n",
    "p1 = udf(_p1, DoubleType())\n",
    "\n",
    "df = tested_df.withColumn(\"p_1\", p1(tested_df.probability))\n",
    "wrong_df = df.orderBy(expr(\"abs(p_1 - label)\"), ascending=False)\n",
    "for i in wrong_df.select(\"image.origin\", \"p_1\", \"label\").limit(10).collect(): print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Apply Deep Image Predictor [Transformer] Example_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.image import ImageSchema\n",
    "from sparkdl import DeepImagePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimage_df = ImageSchema.readImages(imagesDL)\\n\\npredictor = DeepImagePredictor(inputCol=\"image\", outputCol=\"predicted_labels\", modelName=\"InceptionV3\", decodePredictions=True, topK=10)\\npredictions_df = predictor.transform(image_df)\\n\\npredictions_df.select(\"predicted_labels\", \"image.origin\").show()\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "image_df = ImageSchema.readImages(imagesDL)\n",
    "\n",
    "predictor = DeepImagePredictor\\\n",
    "(inputCol=\"image\", outputCol=\"predicted_labels\", modelName=\"InceptionV3\", decodePredictions=True, topK=10)\n",
    "predictions_df = predictor.transform(image_df)\n",
    "\n",
    "predictions_df.select(\"predicted_labels\", \"image.origin\").show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf = p_model.transform(image_df)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df = p_model.transform(image_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Apply Custom Keras Model Example_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "from sparkdl.udf.keras_image_model import registerKerasImageUDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nregisterKerasImageUDF(\"inceptionV3_udf\", InceptionV3(weights=\"imagenet\"))\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "registerKerasImageUDF(\"inceptionV3_udf\", InceptionV3(weights=\"imagenet\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
